"""Markdown Report Generator

Generates concise Markdown summaries from analysis results.
"""

from pathlib import Path
from typing import Any
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class MarkdownReportGenerator:
    """Generates Markdown summary reports from analysis results."""

    def __init__(self, results: dict[str, Any]):
        """Initialize generator.

        Args:
            results: Complete analysis results
        """
        self.results = results
        self.metadata = results.get('metadata', {})
        self.summary = results.get('summary', {})

    def generate(self, output_path: Path | str) -> None:
        """Generate Markdown report and save to file.

        Args:
            output_path: Path where to save the Markdown report
        """
        output_path = Path(output_path)
        content = self.get_markdown()

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"Markdown report generated: {output_path}")

    def get_markdown(self) -> str:
        """Generate Markdown content.

        Returns:
            Markdown string
        """
        lines = []

        # Header
        lines.append(f"# Codebase Analysis Report")
        lines.append(f"")
        lines.append(f"**Service:** {self.metadata.get('service_name', 'Unknown')}")
        lines.append(f"**Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**Files Analyzed:** {self.metadata.get('total_files_analyzed', 0)}")
        lines.append(f"**Modules:** {self.metadata.get('module_count', 0)}")
        lines.append(f"")

        # Executive Summary
        lines.append(f"## Executive Summary")
        lines.append(f"")

        # Module Health
        health = self.summary.get('overall_health', 0)
        health_emoji = self._get_health_emoji(health)
        lines.append(f"### {health_emoji} Overall Health: {health:.1f}/100")
        lines.append(f"")
        lines.append(f"- **Best Module:** {self.summary.get('best_module', 'N/A')} ({self.summary.get('best_score', 0):.1f})")
        lines.append(f"- **Worst Module:** {self.summary.get('worst_module', 'N/A')} ({self.summary.get('worst_score', 0):.1f})")
        lines.append(f"")

        # Technical Debt
        debt_ratio = self.summary.get('debt_ratio', 0)
        sqale = self.summary.get('sqale_rating', 'A')
        debt_emoji = self._get_debt_emoji(sqale)
        lines.append(f"### {debt_emoji} Technical Debt: {debt_ratio:.1f}% (Rating: {sqale})")
        lines.append(f"")
        lines.append(f"- **Remediation Time:** {self.summary.get('total_remediation_hours', 0):.1f} hours ({self.summary.get('total_remediation_days', 0):.1f} days)")
        lines.append(f"")

        # Key Metrics with Explanations
        lines.append(f"## Key Metrics")
        lines.append(f"")

        # Database Coupling
        self._add_db_coupling_section(lines)

        # Code Quality (Complexity)
        self._add_complexity_section(lines)

        # Maintainability
        self._add_maintainability_section(lines)

        # Code Size
        self._add_code_size_section(lines)

        # Tests
        self._add_test_section(lines)

        # Code Smells
        self._add_code_smells_section(lines)

        # Class Metrics
        self._add_class_metrics_section(lines)

        # Module-Level Breakdown
        self._add_module_breakdown(lines)

        # Module Rankings
        module_health = self.results.get('module_health', {})
        rankings = module_health.get('module_rankings', [])
        if rankings:
            lines.append(f"## Module Rankings")
            lines.append(f"")
            lines.append(f"| Rank | Module | Health Score | Category |")
            lines.append(f"|------|--------|--------------|----------|")
            for idx, ranking in enumerate(rankings, 1):
                category_emoji = self._get_category_emoji(ranking.get('category', ''))
                lines.append(
                    f"| {idx} | {ranking.get('module', 'Unknown')} | "
                    f"{ranking.get('score', 0):.1f} | {category_emoji} {ranking.get('category', 'unknown').title()} |"
                )
            lines.append(f"")

        # Footer
        lines.append(f"---")
        lines.append(f"*Generated by COBANA - Codebase Architecture Analysis Tool*")

        return "\n".join(lines)

    def _add_db_coupling_section(self, lines: list[str]) -> None:
        """Add database coupling section with explanation and details."""
        try:
            lines.append("### ğŸ”— Database Coupling")
            lines.append("")

            # Summary stats
            lines.append(f"- **Total Operations:** {self.summary.get('total_operations', 0)}")
            lines.append(f"- **Severity Score:** {self.summary.get('severity_score', 0)}")
            lines.append(f"- **Critical Violations (Writes):** {self.summary.get('violation_count_write', 0)} ğŸ”´")
            lines.append(f"- **Warnings (Reads):** {self.summary.get('violation_count_read', 0)} ğŸŸ¡")
            lines.append("")

            # Explanation
            lines.append("**ğŸ“š What is this?**")
            lines.append("")
            lines.append("Database coupling measures how tightly code is tied to database access. When services directly access each other's tables, they become 'coupled' - changes in one can break another.")
            lines.append("")
            lines.append("**âš¡ Why it matters:**")
            lines.append("")
            lines.append("- **Independent Deployment:** Coupled services can't deploy separately")
            lines.append("- **Test Speed:** Coupled code requires slow integration tests instead of fast unit tests")
            lines.append("- **Reliability:** Changes to shared tables can break multiple services")
            lines.append("")

            # Detailed violations
            db_coupling = self.results.get('db_coupling', {})
            violations = db_coupling.get('violations', [])

            if violations:
                lines.append("**ğŸ”´ Critical Violations:**")
                lines.append("")
                write_violations = [v for v in violations if v.get('operation_type') == 'WRITE']
                if write_violations:
                    for v in write_violations[:10]:  # Limit to top 10
                        lines.append(f"- `{v.get('file', 'unknown')}:{v.get('line', 0)}` - {v.get('operation', 'unknown')} on `{v.get('collection', 'unknown')}`")
                    if len(write_violations) > 10:
                        lines.append(f"  _(... and {len(write_violations) - 10} more)_")
                else:
                    lines.append("_None found_ âœ…")
                lines.append("")

            lines.append("")
        except Exception as e:
            logger.warning(f"Error generating DB coupling section: {e}")
            lines.append("_Error generating DB coupling details_")
            lines.append("")

    def _add_complexity_section(self, lines: list[str]) -> None:
        """Add complexity section with explanation and details."""
        try:
            lines.append("### ğŸ“Š Code Complexity")
            lines.append("")

            # Summary stats
            lines.append(f"- **Average Complexity:** {self.summary.get('avg_complexity', 0):.1f}")
            lines.append(f"- **High Complexity Functions:** {self.summary.get('high_complexity_count', 0)}")
            lines.append(f"- **Max Complexity:** {self.summary.get('max_complexity', 0)}")
            lines.append("")

            # Explanation
            lines.append("**ğŸ“š What is this?**")
            lines.append("")
            lines.append("Cyclomatic complexity measures the number of independent paths through code. Higher complexity means more testing needed and harder to understand.")
            lines.append("")
            lines.append("**âš¡ Why it matters:**")
            lines.append("")
            lines.append("- **Testability:** Complex functions are harder to test thoroughly")
            lines.append("- **Bugs:** High complexity correlates with more defects")
            lines.append("- **Maintenance:** Complex code takes longer to modify safely")
            lines.append("")
            lines.append("**Thresholds:** 1-5 (âœ… Simple), 6-10 (âš ï¸ Moderate), 11-20 (ğŸŸ  Complex), 21+ (ğŸ”´ Very Complex)")
            lines.append("")

            # Detailed high complexity functions
            complexity = self.results.get('complexity', {})
            high_complexity = complexity.get('high_complexity_functions', [])

            if high_complexity:
                lines.append("**ğŸ”´ High Complexity Functions:**")
                lines.append("")
                for func in high_complexity[:15]:  # Top 15
                    emoji = "ğŸ”´" if func.get('complexity', 0) > 20 else "ğŸŸ "
                    lines.append(f"- {emoji} `{func.get('function', 'unknown')}` (complexity: {func.get('complexity', 0)}) - `{func.get('file', 'unknown')}:{func.get('line', 0)}`")
                if len(high_complexity) > 15:
                    lines.append(f"  _(... and {len(high_complexity) - 15} more)_")
                lines.append("")

            lines.append("")
        except Exception as e:
            logger.warning(f"Error generating complexity section: {e}")
            lines.append("_Error generating complexity details_")
            lines.append("")

    def _add_maintainability_section(self, lines: list[str]) -> None:
        """Add maintainability section with explanation and details."""
        lines.append("### ğŸ”§ Maintainability")
        lines.append("")

        # Summary stats
        lines.append(f"- **Average Maintainability Index:** {self.summary.get('avg_mi', 0):.1f}/100")
        lines.append(f"- **Low Maintainability Files:** {self.summary.get('low_mi_count', 0)}")
        lines.append("")

        # Explanation
        lines.append("**ğŸ“š What is this?**")
        lines.append("")
        lines.append("Maintainability Index (0-100) combines complexity, code size, and documentation to estimate how easy code is to maintain.")
        lines.append("")
        lines.append("**âš¡ Why it matters:**")
        lines.append("")
        lines.append("- **Developer Velocity:** Low maintainability slows down development")
        lines.append("- **Onboarding:** New developers struggle with unmaintainable code")
        lines.append("- **Technical Debt:** Low scores indicate accumulating debt")
        lines.append("")
        lines.append("**Thresholds:** 65-100 (âœ… High), 20-64 (âš ï¸ Moderate), 0-19 (ğŸ”´ Low)")
        lines.append("")

        # Detailed low maintainability files
        maintainability = self.results.get('maintainability', {})
        low_mi_files = maintainability.get('low_maintainability_files', [])

        if low_mi_files:
            lines.append("**ğŸ”´ Low Maintainability Files:**")
            lines.append("")
            for file_info in low_mi_files[:10]:
                mi = file_info.get('mi', 0)
                emoji = "ğŸ”´" if mi < 20 else "âš ï¸"
                lines.append(f"- {emoji} `{file_info.get('file', 'unknown')}` (MI: {mi:.1f})")
            if len(low_mi_files) > 10:
                lines.append(f"  _(... and {len(low_mi_files) - 10} more)_")
            lines.append("")

        lines.append("")

    def _add_code_size_section(self, lines: list[str]) -> None:
        """Add code size section with explanation."""
        lines.append("### ğŸ“ Code Size")
        lines.append("")

        lines.append(f"- **Total SLOC:** {self.summary.get('total_sloc', 0):,}")
        lines.append(f"- **Average File Size:** {self.summary.get('avg_file_size', 0):.1f} LOC")
        lines.append(f"- **Comment Ratio:** {self.summary.get('comment_ratio', 0):.1f}%")
        lines.append(f"- **Large Files (>500 LOC):** {self.summary.get('large_files_count', 0)}")
        lines.append("")

        lines.append("**ğŸ“š What is this?**")
        lines.append("")
        lines.append("Source Lines of Code (SLOC) and file size metrics help identify overly large files that may need splitting.")
        lines.append("")
        lines.append("**âš¡ Why it matters:** Large files often indicate mixed responsibilities and are harder to navigate and test.")
        lines.append("")

        # Large files
        code_size = self.results.get('code_size', {})
        large_files = code_size.get('large_files', [])

        if large_files:
            lines.append("**ğŸŸ  Large Files (>500 LOC):**")
            lines.append("")
            for file_info in large_files[:10]:
                lines.append(f"- `{file_info.get('file', 'unknown')}` ({file_info.get('sloc', 0)} LOC)")
            if len(large_files) > 10:
                lines.append(f"  _(... and {len(large_files) - 10} more)_")
            lines.append("")

        lines.append("")

    def _add_test_section(self, lines: list[str]) -> None:
        """Add test analysis section with explanation."""
        lines.append("### ğŸ§ª Tests")
        lines.append("")

        lines.append(f"- **Test Files:** {self.summary.get('total_test_files', 0)}")
        lines.append(f"- **Unit Tests:** {self.summary.get('unit_percentage', 0):.1f}%")
        lines.append(f"- **Integration Tests:** {self.summary.get('integration_percentage', 0):.1f}%")
        lines.append(f"- **Testability Score:** {self.summary.get('testability_score', 0):.1f}%")
        lines.append("")

        lines.append("**ğŸ“š What is this?**")
        lines.append("")
        lines.append("Test analysis categorizes tests (unit vs integration) and measures testability - what percentage of code can be unit tested without database access.")
        lines.append("")
        lines.append("**âš¡ Why it matters:**")
        lines.append("")
        lines.append("- **Fast Feedback:** Unit tests run in milliseconds, integration tests in seconds/minutes")
        lines.append("- **Reliability:** Untestable code (mixed with DB access) is harder to verify")
        lines.append("- **Refactoring:** Well-tested code can be safely modified")
        lines.append("")
        lines.append("")

    def _add_code_smells_section(self, lines: list[str]) -> None:
        """Add code smells section with explanation."""
        lines.append("### ğŸ‘ƒ Code Smells")
        lines.append("")

        lines.append(f"- **Total Smells:** {self.summary.get('total_smells', 0)}")
        lines.append(f"  - Long Methods (>50 LOC): {self.summary.get('long_methods', 0)}")
        lines.append(f"  - Long Parameter Lists (>5 params): {self.summary.get('long_parameter_lists', 0)}")
        lines.append(f"  - Deep Nesting (>4 levels): {self.summary.get('deep_nesting', 0)}")
        lines.append("")

        lines.append("**ğŸ“š What is this?**")
        lines.append("")
        lines.append("Code smells are patterns that indicate potential problems: long methods, too many parameters, or deeply nested logic.")
        lines.append("")
        lines.append("**âš¡ Why it matters:** These patterns make code harder to understand, test, and modify.")
        lines.append("")

        # Detailed smells
        code_smells = self.results.get('code_smells', {})
        long_methods = code_smells.get('long_methods', [])

        if long_methods:
            lines.append("**ğŸŸ  Long Methods (>50 LOC):**")
            lines.append("")
            for smell in long_methods[:10]:
                lines.append(f"- `{smell.get('function', 'unknown')}` ({smell.get('sloc', 0)} LOC) - `{smell.get('module', 'unknown')}` (line {smell.get('line', 0)})")
            if len(long_methods) > 10:
                lines.append(f"  _(... and {len(long_methods) - 10} more)_")
            lines.append("")

        lines.append("")

    def _add_class_metrics_section(self, lines: list[str]) -> None:
        """Add class metrics section with explanation."""
        lines.append("### ğŸ›ï¸ Class Metrics")
        lines.append("")

        lines.append(f"- **Total Classes:** {self.summary.get('total_classes', 0)}")
        lines.append(f"- **God Classes (>20 methods):** {self.summary.get('god_classes_count', 0)} ğŸ”´")
        lines.append(f"- **Low Cohesion Classes:** {self.summary.get('low_cohesion_count', 0)}")
        lines.append(f"- **Average LCOM:** {self.summary.get('avg_lcom', 0):.2f}")
        lines.append(f"- **Average WMC:** {self.summary.get('avg_wmc', 0):.1f}")
        lines.append("")

        lines.append("**ğŸ“š What is this?**")
        lines.append("")
        lines.append("- **God Classes:** Classes with too many methods (>20), indicating too many responsibilities")
        lines.append("- **LCOM (Lack of Cohesion):** Measures if class methods use the same data (lower is better)")
        lines.append("- **WMC (Weighted Methods per Class):** Sum of method complexities")
        lines.append("")
        lines.append("**âš¡ Why it matters:** God classes violate Single Responsibility Principle and are hard to maintain.")
        lines.append("")

        # God classes
        class_metrics = self.results.get('class_metrics', {})
        god_classes = class_metrics.get('god_classes', [])

        if god_classes:
            lines.append("**ğŸ”´ God Classes:**")
            lines.append("")
            for cls in god_classes[:10]:
                lines.append(f"- `{cls.get('class', 'unknown')}` ({cls.get('methods', 0)} methods, WMC: {cls.get('wmc', 0)}) - `{cls.get('file', 'unknown')}:{cls.get('line', 0)}`")
            if len(god_classes) > 10:
                lines.append(f"  _(... and {len(god_classes) - 10} more)_")
            lines.append("")

        lines.append("")

    def _add_module_breakdown(self, lines: list[str]) -> None:
        """Add detailed per-module breakdown."""
        try:
            module_health = self.results.get('module_health', {})
            by_module = module_health.get('by_module', {})

            if not by_module:
                return

            lines.append("## Module-Level Breakdown")
            lines.append("")
            lines.append("Detailed metrics for each module to identify areas needing attention.")
            lines.append("")

            # Get data from individual analyzers
            complexity_by_module = self.results.get('complexity', {}).get('by_module', {})
            maintainability_by_module = self.results.get('maintainability', {}).get('by_module', {})
            db_by_module = self.results.get('db_coupling', {}).get('by_module', {})
            smells_by_module = self.results.get('code_smells', {}).get('by_module', {})
            tests_by_module = self.results.get('tests', {}).get('by_module', {})

            # Sort modules by health score (worst first)
            sorted_modules = sorted(
                by_module.items(),
                key=lambda x: x[1].get('score', 0)
            )

            for module_name, module_data in sorted_modules:
                health = module_data.get('score', 0)
                emoji = self._get_health_emoji(health)

                lines.append(f"### {emoji} Module: `{module_name}` (Health: {health:.1f}/100)")
                lines.append("")

                # Get module-specific data
                complexity_data = complexity_by_module.get(module_name, {})
                maintainability_data = maintainability_by_module.get(module_name, {})
                db_data = db_by_module.get(module_name, {})
                smells_data = smells_by_module.get(module_name, {})
                tests_data = tests_by_module.get(module_name, {})

                # Key stats in table
                lines.append("| Metric | Value |")
                lines.append("|--------|-------|")
                lines.append(f"| Complexity | {complexity_data.get('avg_complexity', 0):.1f} avg |")
                lines.append(f"| Maintainability | {maintainability_data.get('avg_mi', 0):.1f}/100 |")
                lines.append(f"| DB Operations | {db_data.get('total_operations', 0) if db_data else 0} |")
                lines.append(f"| DB Severity | {db_data.get('severity_score', 0) if db_data else 0} |")
                lines.append(f"| Code Smells | {smells_data.get('total_smells', 0)} |")
                lines.append(f"| Test Files | {tests_data.get('test_files', 0) if tests_data else 0} |")
                lines.append("")

            lines.append("")
        except Exception as e:
            logger.warning(f"Error generating module breakdown: {e}")
            lines.append("_Error generating module breakdown_")
            lines.append("")

    def _get_health_emoji(self, score: float) -> str:
        """Get emoji for health score."""
        if score >= 80:
            return "ğŸŸ¢"
        elif score >= 60:
            return "ğŸŸ¡"
        elif score >= 40:
            return "ğŸŸ "
        else:
            return "ğŸ”´"

    def _get_debt_emoji(self, rating: str) -> str:
        """Get emoji for SQALE rating."""
        match rating:
            case 'A' | 'B':
                return "ğŸŸ¢"
            case 'C':
                return "ğŸŸ¡"
            case 'D':
                return "ğŸŸ "
            case _:
                return "ğŸ”´"

    def _get_category_emoji(self, category: str) -> str:
        """Get emoji for health category."""
        match category.lower():
            case 'excellent':
                return "ğŸŒŸ"
            case 'good':
                return "âœ…"
            case 'warning':
                return "âš ï¸"
            case 'critical':
                return "ğŸ”´"
            case _:
                return "ğŸ†˜"
